{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "language-model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hieutrgvu/text-generation-and-correction/blob/main/language-model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AwUhQkprdY_e"
      },
      "source": [
        "# **0. Running from Google Colab**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DD-idowHa6Dq",
        "outputId": "77f8880c-f825-4e7b-8dbf-fc4ff7c86851"
      },
      "source": [
        "!git clone https://github.com/hieutrgvu/text-generation-and-correction.git"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'text-generation-and-correction'...\n",
            "remote: Enumerating objects: 1042, done.\u001b[K\n",
            "remote: Counting objects: 100% (1042/1042), done.\u001b[K\n",
            "remote: Compressing objects: 100% (1010/1010), done.\u001b[K\n",
            "remote: Total 1042 (delta 26), reused 1031 (delta 22), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (1042/1042), 6.01 MiB | 15.04 MiB/s, done.\n",
            "Resolving deltas: 100% (26/26), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FjximMx9b19V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2338cf02-d3a1-47e8-b819-895fb8b8814b"
      },
      "source": [
        "cd \"text-generation-and-correction\""
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/text-generation-and-correction\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F82bwKXpMLvj",
        "outputId": "4babf35a-b3a0-40e8-bb83-b9692c1d64c7"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I2tr28OWe6M9"
      },
      "source": [
        "# **1. Import**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "laZeC49Ce1w7"
      },
      "source": [
        "import os\n",
        "import random\n",
        "import re\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import time\n",
        "from scipy import special"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YYASI8qTd04F"
      },
      "source": [
        "# **2. Load, Clean and Augment Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wFIzb1jtdCaj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15bef71e-b485-4b24-ae15-968e4ee64979"
      },
      "source": [
        "# load\n",
        "lines = []\n",
        "data_dir = \"./tiki-data\"\n",
        "for file in os.listdir(data_dir):\n",
        "  if file.startswith(\"sach-\"):\n",
        "    with open(data_dir+\"/\"+file) as f:\n",
        "      lines.extend(f.readlines())\n",
        "\n",
        "print(\"Number of lines: \", len(lines))\n",
        "lines[:10]"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of lines:  10079\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['\"Madame Chic - Rất Thần Thái, Rất Paris\"\\n',\n",
              " 'Hành Trình Của Linh Hồn\\n',\n",
              " 'Thai Giáo Theo Chuyên Gia - 280 Ngày - Mỗi Ngày Đọc Một Trang\\n',\n",
              " 'EAT CLEAN Thực Đơn 14 Ngày Thanh Lọc Cơ Thể Và Giảm Cân\\n',\n",
              " 'Thánh Kinh Dưỡng Da\\n',\n",
              " '\"Green Smoothies - Giảm Cân, Làm Đẹp Da, Tăng Cường Sức Đề Kháng Với 7 Ngày Uống Sinh Tố Xanh\"\\n',\n",
              " 'BREW - Tuyệt Đỉnh Cà Phê Tại Nhà\\n',\n",
              " 'Khởi Sự Ăn Chay\\n',\n",
              " 'Đừng Chỉ Mặc Màu Đen\\n',\n",
              " 'Chào Juice\\n']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LVPM-G5YnTIq",
        "outputId": "10c2d926-7b23-4cf7-b925-10975e248e2d"
      },
      "source": [
        "# clean\n",
        "bos = \"{\"\n",
        "eos = \"}\"\n",
        "regex = \"[^0-9a-zạảãàáâậầấẩẫăắằặẳẵóòọõỏôộổỗồốơờớợởỡéèẻẹẽêếềệểễúùụủũưựữửừứíìịỉĩýỳỷỵỹđ]\"\n",
        "for i in range(len(lines)):\n",
        "  lines[i] = re.sub(regex, \" \", lines[i].lower()).strip()\n",
        "  lines[i] = bos + re.sub(' +', ' ', lines[i])  + eos\n",
        "lines[:10]"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['{madame chic rất thần thái rất paris}',\n",
              " '{hành trình của linh hồn}',\n",
              " '{thai giáo theo chuyên gia 280 ngày mỗi ngày đọc một trang}',\n",
              " '{eat clean thực đơn 14 ngày thanh lọc cơ thể và giảm cân}',\n",
              " '{thánh kinh dưỡng da}',\n",
              " '{green smoothies gia m cân la m đe p da tăng cươ ng sư c đê kha ng vơ i 7 nga y uô ng sinh tô xanh}',\n",
              " '{brew tuyê t đi nh ca phê ta i nha}',\n",
              " '{khởi sự ăn chay}',\n",
              " '{đừng chỉ mặc màu đen}',\n",
              " '{chào juice}']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "id": "45MNis1mj7bG",
        "outputId": "c119f3be-39e3-4588-da01-ece898a6a541"
      },
      "source": [
        "# augment\n",
        "text = []\n",
        "for line in lines:\n",
        "  line = [line]*10\n",
        "  text.extend(line)\n",
        "random.shuffle(text)\n",
        "text = \"\".join(text)\n",
        "text[:500]"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'{vietmath cùng con giỏi tư duy toán học tập 1}{rich habits thói quen thành công của những triệu phú tự thân}{giải mật ngoại hạng anh}{đời sống bí ẩn của cây}{sự giàu và nghèo của các dân tộc}{brew tuyê t đi nh ca phê ta i nha}{từ chiến lược marketing đến doanh nghiệp thành công}{science encyclopedia bách khoa thư về khoa học trái đất và vũ trụ}{triệu phú thức tỉnh bí kíp để khơi dòng suối nguồn thịnh vượng trong tâm thức}{bạn đắt giá bao nhiêu tặng kèm bộ bookmark tiki love books}{thị dân 3 0}{k'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r8OONYs7FsC8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c205dcc8-378b-4026-8950-19ee679e0ce9"
      },
      "source": [
        "#Create vocabulary \n",
        "vocab = sorted(set(text))\n",
        "print(\"vocab len:\", len(vocab))\n",
        "#create an index for each character\n",
        "char2idx = {u:i for i,u in enumerate(vocab)}\n",
        "idx2char = np.array(vocab)\n",
        "conver_text_to_int = np.array([char2idx[char] for char in text])"
      ],
      "execution_count": 225,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "vocab len: 106\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wvtTsAATGmOu"
      },
      "source": [
        "#convert the text vector into a stream of character indices.\n",
        "char_dataset = tf.data.Dataset.from_tensor_slices(conver_text_to_int)\n",
        "#Each sample has 100 chars\n",
        "seq_length = 100\n",
        "#convert char to sentences of 100 chars\n",
        "sequences = char_dataset.batch(seq_length+1, drop_remainder=True)\n",
        "#split into input and targer, each length 100\n",
        "def split_input_target(chunk):\n",
        "    input_text = chunk[:-1]\n",
        "    target_text = chunk[1:]\n",
        "    return input_text, target_text\n",
        "\n",
        "dataset = sequences.map(split_input_target)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yletLjrJG9-f"
      },
      "source": [
        "#shuffle and batch samples\n",
        "BATCH_SIZE =30\n",
        "dataset = dataset.shuffle(10000).batch(BATCH_SIZE,drop_remainder=True) \n",
        "embedding_dim = 256\n",
        "rnn_units=1024"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3si9vffdHEJq"
      },
      "source": [
        "# **3. Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IKojRll5HHm8"
      },
      "source": [
        "def build_model(embedding_dim,rnn_units,batch_size,vocab_size):\n",
        "  model = tf.keras.Sequential(\n",
        "  [tf.keras.layers.Embedding(vocab_size,embedding_dim,batch_input_shape=[batch_size,None]),\n",
        "     tf.keras.layers.GRU(rnn_units,\n",
        "                            return_sequences=True,\n",
        "                            stateful=True,\n",
        "                            recurrent_initializer='glorot_uniform'),\n",
        "        tf.keras.layers.Dense(vocab_size)  \n",
        "  ])\n",
        "  return model\n",
        "\n",
        "def build_lstm_model(embedding_dim,rnn_units,batch_size,vocab_size):\n",
        "  model = tf.keras.Sequential([tf.keras.layers.Embedding(vocab_size,embedding_dim,batch_input_shape=[batch_size,None]),\n",
        "     tf.keras.layers.LSTM(rnn_units,\n",
        "                            return_sequences=True,\n",
        "                            stateful=True,\n",
        "                            recurrent_initializer='glorot_uniform'),\n",
        "        tf.keras.layers.Dense(vocab_size)  \n",
        "    ])\n",
        "  return model\n",
        "  \n",
        "\n",
        "def loss(labels, logits):\n",
        "    return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2lmbgr6gsuzS"
      },
      "source": [
        "## **3.1. GRU**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Wa-Vk85HleF",
        "outputId": "ec173654-0b41-45f5-ea3d-d27a9d3df236"
      },
      "source": [
        "#Train model GRU layer\n",
        "model = build_model(embedding_dim,rnn_units,BATCH_SIZE,len(vocab))\n",
        "model.summary()\n",
        "model_save_dir = '/content/drive/MyDrive/LSTM/RNN'\n",
        "checkpoint_prefix = os.path.join(model_save_dir, \"ckpt_{epoch}\")\n",
        "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_prefix,\n",
        "    save_weights_only=True)\n",
        "early_stop_callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)\n",
        "model.compile(optimizer='adam', loss=loss)\n",
        "history = model.fit(dataset, epochs=30,callbacks=[checkpoint_callback, early_stop_callback])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_2 (Embedding)      (30, None, 256)           27136     \n",
            "_________________________________________________________________\n",
            "gru_2 (GRU)                  (30, None, 1024)          3938304   \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (30, None, 106)           108650    \n",
            "=================================================================\n",
            "Total params: 4,074,090\n",
            "Trainable params: 4,074,090\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/30\n",
            "1583/1583 [==============================] - 49s 31ms/step - loss: 1.2216\n",
            "Epoch 2/30\n",
            "1583/1583 [==============================] - 49s 31ms/step - loss: 0.5236\n",
            "Epoch 3/30\n",
            "1583/1583 [==============================] - 49s 31ms/step - loss: 0.4420\n",
            "Epoch 4/30\n",
            "1583/1583 [==============================] - 49s 31ms/step - loss: 0.4282\n",
            "Epoch 5/30\n",
            "1583/1583 [==============================] - 49s 31ms/step - loss: 0.4324\n",
            "Epoch 6/30\n",
            "1583/1583 [==============================] - 49s 31ms/step - loss: 0.4628\n",
            "Epoch 7/30\n",
            "1583/1583 [==============================] - 49s 31ms/step - loss: 0.6685\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cpTXQTQksJZG",
        "outputId": "ae0b5f02-447c-4b8a-f270-aed67f01282e"
      },
      "source": [
        "model_save_dir = '/content/drive/MyDrive/LSTM/RNN'\n",
        "generate_model = build_model(embedding_dim,rnn_units,1,len(vocab))\n",
        "generate_model.load_weights(tf.train.latest_checkpoint(model_save_dir))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7fae90092a58>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M7kpgG0Ss_W0"
      },
      "source": [
        "## **3.2. LSTM**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yRmNoBG5wbdW",
        "outputId": "84635601-4e74-408b-bbf1-f3459e41a102"
      },
      "source": [
        "#Train model LSTM \n",
        "model_lstm = build_lstm_model(embedding_dim,rnn_units,BATCH_SIZE,len(vocab))\n",
        "model_lstm.summary()\n",
        "#train model \n",
        "#add checkpoint save\n",
        "model_save_dir = '/content/drive/My Drive/ML/RNN/checkpointlstm1'\n",
        "checkpoint_prefix = os.path.join(model_save_dir, \"ckpt_{epoch}\")\n",
        "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_prefix,\n",
        "    save_weights_only=True)\n",
        "\n",
        "early_stop_callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=2)\n",
        "model_lstm.compile(optimizer='adam', loss=loss)\n",
        "model_lstm.fit(dataset, epochs=30,callbacks=[checkpoint_callback, early_stop_callback])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_20\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_20 (Embedding)     (30, None, 256)           27136     \n",
            "_________________________________________________________________\n",
            "lstm_5 (LSTM)                (30, None, 1024)          5246976   \n",
            "_________________________________________________________________\n",
            "dense_20 (Dense)             (30, None, 106)           108650    \n",
            "=================================================================\n",
            "Total params: 5,382,762\n",
            "Trainable params: 5,382,762\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/30\n",
            "1583/1583 [==============================] - 59s 37ms/step - loss: 1.1461\n",
            "Epoch 2/30\n",
            "1583/1583 [==============================] - 59s 37ms/step - loss: 0.5018\n",
            "Epoch 3/30\n",
            "1583/1583 [==============================] - 59s 37ms/step - loss: 0.4193\n",
            "Epoch 4/30\n",
            "1583/1583 [==============================] - 59s 37ms/step - loss: 0.3967\n",
            "Epoch 5/30\n",
            "1583/1583 [==============================] - 59s 37ms/step - loss: 0.3848\n",
            "Epoch 6/30\n",
            "1583/1583 [==============================] - 59s 37ms/step - loss: 0.3776\n",
            "Epoch 7/30\n",
            "1583/1583 [==============================] - 59s 37ms/step - loss: 0.3725\n",
            "Epoch 8/30\n",
            "1583/1583 [==============================] - 59s 37ms/step - loss: 0.3700\n",
            "Epoch 9/30\n",
            "1583/1583 [==============================] - 59s 37ms/step - loss: 0.3680\n",
            "Epoch 10/30\n",
            "1583/1583 [==============================] - 59s 37ms/step - loss: 0.3687\n",
            "Epoch 11/30\n",
            "1583/1583 [==============================] - 59s 37ms/step - loss: 0.3693\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f5723618fd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-3uXRI5atll0",
        "outputId": "e1a63b80-3a12-492e-fd3a-2406ea75f4a8"
      },
      "source": [
        "model_save_dir = '/content/drive/My Drive/ML/RNN/checkpointlstm1'\n",
        "generate_model_lstm = build_lstm_model(embedding_dim,rnn_units,1,len(vocab))\n",
        "generate_model_lstm.load_weights(tf.train.latest_checkpoint(model_save_dir)).expect_partial()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7fae4011d358>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-13Y5D3att4h"
      },
      "source": [
        "# **4. Text Generation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hF9RIvhsHkKN"
      },
      "source": [
        "def generate_text(model, start_string):\n",
        "    num_generate = 100\n",
        "    input_eval = [char2idx[s] for s in start_string]\n",
        "    input_eval = tf.expand_dims(input_eval, 0)\n",
        "    print(input_eval.shape)\n",
        "    text_generated = []\n",
        "    model.reset_states() #delete hidden state\n",
        "\n",
        "    for i in range(num_generate):\n",
        "        predictions = model(input_eval)\n",
        "        predictions = tf.squeeze(predictions, 0)# drop batch dimensionality\n",
        "        predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
        "        prob = special.softmax(predictions[-1])\n",
        "        input_eval = tf.expand_dims([predicted_id], 0)\n",
        "        text_generated.append(idx2char[predicted_id])\n",
        "        if idx2char[predicted_id] == \"}\":\n",
        "          text_generated = text_generated[:-1]\n",
        "          break\n",
        "        if max(prob) < 0.2:\n",
        "          break\n",
        "    return (start_string + ''.join(text_generated))"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7uNdE7rKuLNk"
      },
      "source": [
        "## **4.1. GRU**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_uocah2v3dj-",
        "outputId": "90ba3c81-61ed-4631-b89f-53baccc8c6ae"
      },
      "source": [
        "#Build new model to generate\n",
        "result_of_gru_char = generate_text(generate_model, start_string=u\"dế mèn phiê\")\n",
        "print(result_of_gru_char)\n",
        "result_of_gru_char = generate_text(generate_model, start_string=u\"nhà kh\")\n",
        "print(result_of_gru_char)\n",
        "result_of_gru_char = generate_text(generate_model, start_string=u\"sách tập làm v\")\n",
        "print(result_of_gru_char)\n",
        "result_of_gru_char = generate_text(generate_model, start_string=u\"thanh lọ\")\n",
        "print(result_of_gru_char)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1, 11)\n",
            "dế mèn phiêu lưu ký tái nhà ăn cơm học\n",
            "(1, 6)\n",
            "nhà khi đúng b\n",
            "(1, 14)\n",
            "sách tập làm việc nhà thuật x\n",
            "(1, 8)\n",
            "thanh lọc ốc diệu của philập tư duy vệ sách mẹ nhà trường chứng khoán nhật kỳ lực chi kháng kèm s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ve7EofiSuTF0"
      },
      "source": [
        "## **4.2. LSTM**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IKsJW6U3znTF",
        "outputId": "19b36df6-a68c-4298-a6b3-84a80af665f2"
      },
      "source": [
        "result_of_gru_char = generate_text(generate_model_lstm, start_string=u\"dế mèn phiê\")\n",
        "print(result_of_gru_char)\n",
        "result_of_gru_char = generate_text(generate_model_lstm, start_string=u\"nhà kh\")\n",
        "print(result_of_gru_char)\n",
        "result_of_gru_char = generate_text(generate_model_lstm, start_string=u\"sách tập làm v\")\n",
        "print(result_of_gru_char)\n",
        "result_of_gru_char = generate_text(generate_model_lstm, start_string=u\"thanh lọ\")\n",
        "print(result_of_gru_char)"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1, 11)\n",
            "dế mèn phiêu lưu ký khi những điều lấp lánh được gọi tên tái bản\n",
            "(1, 6)\n",
            "nhà khoa học\n",
            "(1, 14)\n",
            "sách tập làm văn\n",
            "(1, 8)\n",
            "thanh lọc cơ thể và giảm cân\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KoiXPIkFuvUT"
      },
      "source": [
        "# **5. Spelling correction**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "obAvlTrwmGhG"
      },
      "source": [
        "## **5.1. Left to Right without Lookahead**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K10q2fX2y0Ry"
      },
      "source": [
        "def correct_text(model, text, begin=7, threshold=0.001):\n",
        "  correct = text[:begin]\n",
        "  misspell = text[:begin]\n",
        "  misspell_detected = False\n",
        "\n",
        "  print(\"Assume the first \" + str(begin) + \" chars are correct\")\n",
        "  seq = [char2idx[c] for c in text[:begin]]\n",
        "  seq = tf.expand_dims(seq, 0)\n",
        "  model.reset_states()\n",
        "\n",
        "  for i in range(begin, len(text)):\n",
        "    predictions = model(seq)\n",
        "    predictions = tf.squeeze(predictions, 0)[-1]\n",
        "    probs = special.softmax(predictions)\n",
        "\n",
        "    if probs[char2idx[text[i]]] < threshold:\n",
        "      misspell_detected = True\n",
        "      misspell += \"(\" + text[i] + \")\"\n",
        "      corrected_char = tf.math.top_k(predictions).indices[0]\n",
        "      correct += idx2char[corrected_char]\n",
        "      print(f\"{misspell} --> {correct}\")\n",
        "    else:\n",
        "      misspell += text[i]\n",
        "      correct += text[i]\n",
        "\n",
        "    seq = tf.expand_dims([char2idx[correct[-1]]], 0)\n",
        "\n",
        "  if not misspell_detected:\n",
        "    misspell = \"\"\n",
        "  \n",
        "  print(\"misspell: \", misspell)\n",
        "  print(\"correct: \", correct)\n",
        "  print()\n",
        "  return correct, misspell"
      ],
      "execution_count": 206,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BXCFlmCGm7r4",
        "outputId": "27fb4d6d-8540-4763-e80d-2d7bfb120083"
      },
      "source": [
        "# Good cases\n",
        "correct_text(generate_model_lstm, \"dế mèn phieu lưu ký táo bản\")\n",
        "correct_text(generate_model_lstm, \"dòng suoi nguồn thịnh vuong\")\n",
        "correct_text(generate_model_lstm, \"dòng suối nguồn thịnh vượng\")\n",
        "print()"
      ],
      "execution_count": 207,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Assume the first 7 chars are correct\n",
            "dế mèn phi(e) --> dế mèn phiê\n",
            "dế mèn phi(e)u lưu ký tá(o) --> dế mèn phiêu lưu ký tái\n",
            "misspell:  dế mèn phi(e)u lưu ký tá(o) bản\n",
            "correct:  dế mèn phiêu lưu ký tái bản\n",
            "\n",
            "Assume the first 7 chars are correct\n",
            "dòng su(o) --> dòng suố\n",
            "dòng su(o)i nguồn thịnh v(u) --> dòng suối nguồn thịnh vư\n",
            "dòng su(o)i nguồn thịnh v(u)(o) --> dòng suối nguồn thịnh vượ\n",
            "misspell:  dòng su(o)i nguồn thịnh v(u)(o)ng\n",
            "correct:  dòng suối nguồn thịnh vượng\n",
            "\n",
            "Assume the first 7 chars are correct\n",
            "misspell:  \n",
            "correct:  dòng suối nguồn thịnh vượng\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QDsZrqKlmRTc",
        "outputId": "1932a9b3-4c1c-4a61-8a30-a3d502a16fc3"
      },
      "source": [
        "# bad case\n",
        "correct_text(generate_model_lstm, \"dòng suối nnguồn thịnh vượng\")\n",
        "correct_text(generate_model_lstm, \"dòng suối naaguồn thịnh vượng\")\n",
        "print()"
      ],
      "execution_count": 224,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Assume the first 7 chars are correct\n",
            "dòng suối n(n) --> dòng suối ng\n",
            "dòng suối n(n)(g) --> dòng suối ngu\n",
            "dòng suối n(n)(g)(u) --> dòng suối nguồ\n",
            "dòng suối n(n)(g)(u)(ồ) --> dòng suối nguồn\n",
            "dòng suối n(n)(g)(u)(ồ)(n) --> dòng suối nguồn \n",
            "dòng suối n(n)(g)(u)(ồ)(n)( ) --> dòng suối nguồn t\n",
            "dòng suối n(n)(g)(u)(ồ)(n)( )(t) --> dòng suối nguồn th\n",
            "dòng suối n(n)(g)(u)(ồ)(n)( )(t)(h) --> dòng suối nguồn thị\n",
            "dòng suối n(n)(g)(u)(ồ)(n)( )(t)(h)(ị) --> dòng suối nguồn thịn\n",
            "dòng suối n(n)(g)(u)(ồ)(n)( )(t)(h)(ị)(n) --> dòng suối nguồn thịnh\n",
            "dòng suối n(n)(g)(u)(ồ)(n)( )(t)(h)(ị)(n)(h) --> dòng suối nguồn thịnh \n",
            "dòng suối n(n)(g)(u)(ồ)(n)( )(t)(h)(ị)(n)(h)( ) --> dòng suối nguồn thịnh v\n",
            "dòng suối n(n)(g)(u)(ồ)(n)( )(t)(h)(ị)(n)(h)( )(v) --> dòng suối nguồn thịnh vư\n",
            "dòng suối n(n)(g)(u)(ồ)(n)( )(t)(h)(ị)(n)(h)( )(v)(ư) --> dòng suối nguồn thịnh vượ\n",
            "dòng suối n(n)(g)(u)(ồ)(n)( )(t)(h)(ị)(n)(h)( )(v)(ư)(ợ) --> dòng suối nguồn thịnh vượn\n",
            "dòng suối n(n)(g)(u)(ồ)(n)( )(t)(h)(ị)(n)(h)( )(v)(ư)(ợ)(n) --> dòng suối nguồn thịnh vượng\n",
            "dòng suối n(n)(g)(u)(ồ)(n)( )(t)(h)(ị)(n)(h)( )(v)(ư)(ợ)(n)(g) --> dòng suối nguồn thịnh vượng \n",
            "misspell:  dòng suối n(n)(g)(u)(ồ)(n)( )(t)(h)(ị)(n)(h)( )(v)(ư)(ợ)(n)(g)\n",
            "correct:  dòng suối nguồn thịnh vượng \n",
            "\n",
            "Assume the first 7 chars are correct\n",
            "dòng suối n(a) --> dòng suối ng\n",
            "dòng suối n(a)(a) --> dòng suối ngu\n",
            "dòng suối n(a)(a)(g) --> dòng suối nguồ\n",
            "dòng suối n(a)(a)(g)(u) --> dòng suối nguồn\n",
            "dòng suối n(a)(a)(g)(u)(ồ) --> dòng suối nguồn \n",
            "dòng suối n(a)(a)(g)(u)(ồ)(n) --> dòng suối nguồn t\n",
            "dòng suối n(a)(a)(g)(u)(ồ)(n)( ) --> dòng suối nguồn th\n",
            "dòng suối n(a)(a)(g)(u)(ồ)(n)( )(t) --> dòng suối nguồn thị\n",
            "dòng suối n(a)(a)(g)(u)(ồ)(n)( )(t)(h) --> dòng suối nguồn thịn\n",
            "dòng suối n(a)(a)(g)(u)(ồ)(n)( )(t)(h)(ị) --> dòng suối nguồn thịnh\n",
            "dòng suối n(a)(a)(g)(u)(ồ)(n)( )(t)(h)(ị)(n) --> dòng suối nguồn thịnh \n",
            "dòng suối n(a)(a)(g)(u)(ồ)(n)( )(t)(h)(ị)(n)h( ) --> dòng suối nguồn thịnh hư\n",
            "dòng suối n(a)(a)(g)(u)(ồ)(n)( )(t)(h)(ị)(n)h( )(v) --> dòng suối nguồn thịnh hư \n",
            "misspell:  dòng suối n(a)(a)(g)(u)(ồ)(n)( )(t)(h)(ị)(n)h( )(v)ượng\n",
            "correct:  dòng suối nguồn thịnh hư ượng\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s5GP1yAOmoFe"
      },
      "source": [
        "## **5.2 Left to Right with Lookahead**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CIHtQlCpeKUu",
        "outputId": "b81d2b0f-c02a-4d26-9620-a10e5dc03237"
      },
      "source": [
        "def get_prob_of_text(model, text, begin):\n",
        "  prob = 1\n",
        "  if begin >= len(text):\n",
        "    return prob\n",
        "  \n",
        "  seq = [char2idx[c] for c in text]\n",
        "  model.reset_states()\n",
        "  predictions = model(tf.expand_dims(seq, 0))\n",
        "  predictions = tf.squeeze(predictions, 0)\n",
        "  for i in range(begin, len(text)):\n",
        "    probs = special.softmax(predictions[i-1])\n",
        "    prob *= probs[char2idx[text[i]]]\n",
        "\n",
        "  return prob\n",
        "\n",
        "test = [\"dế mèn phiêu lưu ký\", \"dế mèn phiêu lu ký\", \"dế mèn phiêu ưu ký\"]\n",
        "for t in test:\n",
        "  print(t, \":\", get_prob_of_text(generate_model_lstm, t, 10))"
      ],
      "execution_count": 197,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dế mèn phiêu lưu ký : 0.8976038268369191\n",
            "dế mèn phiêu lu ký : 3.850490837557988e-06\n",
            "dế mèn phiêu ưu ký : 2.5335562370135195e-07\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PWkVew0HEScH"
      },
      "source": [
        "def correct_text_lookahead(model, text, begin=7, threshold=0.001):\n",
        "  correct = text[:begin]\n",
        "  misspell = text[:begin]\n",
        "  misspell_detected = False\n",
        "\n",
        "  print(\"Assume the first \" + str(begin) + \" chars are correct\")\n",
        "\n",
        "  seq = [char2idx[c] for c in text[:begin]]\n",
        "  for i in range(begin, len(text)):\n",
        "    model.reset_states()\n",
        "    predictions = model(tf.expand_dims(seq, 0))\n",
        "    predictions = tf.squeeze(predictions, 0)[-1]\n",
        "    probs = special.softmax(predictions)\n",
        "\n",
        "    if probs[char2idx[text[i]]] < threshold:\n",
        "      misspell_detected = True\n",
        "      top_k_next_chars = tf.math.top_k(probs, k=3).indices\n",
        "      options = [correct + idx2char[c] + text[i+1:] for c in top_k_next_chars] # replace text[i]\n",
        "      options.append(correct + text[i+1:]) # remove text[i]\n",
        "      options_probs = [get_prob_of_text(model, option, len(correct)) for option in options]\n",
        "      chosen = np.argmax(options_probs)\n",
        "      misspell += \"(\" + text[i] + \")\"\n",
        "      if chosen != len(options)-1:\n",
        "        corrected_char = top_k_next_chars[chosen]\n",
        "        correct += idx2char[corrected_char]\n",
        "      print(f\"{misspell} --> {correct}\")\n",
        "    else:\n",
        "      misspell += text[i]\n",
        "      correct += text[i]\n",
        "\n",
        "    seq.append(char2idx[correct[-1]])\n",
        "\n",
        "  if not misspell_detected:\n",
        "    misspell = \"\"\n",
        "  \n",
        "  print(f\"Misspell: {misspell}\\nCorrect: {correct}\\n\")\n",
        "  return correct, misspell"
      ],
      "execution_count": 211,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "36RIfCWgRKwf",
        "outputId": "35aa673b-c70e-48f5-e0fe-3e2fe17c5c85"
      },
      "source": [
        "correct_text_lookahead(generate_model_lstm, \"dế mèn phieu lưu ký táo bản\")\n",
        "correct_text_lookahead(generate_model_lstm, \"dòng suoi nguồn thịnh vuợng\")\n",
        "correct_text_lookahead(generate_model_lstm, \"dòng suối nguồn thịnh vượng\")"
      ],
      "execution_count": 226,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Assume the first 7 chars are correct\n",
            "dế mèn phi(e) --> dế mèn phiê\n",
            "dế mèn phi(e)u lưu ký tá(o) --> dế mèn phiêu lưu ký tái\n",
            "Misspell: dế mèn phi(e)u lưu ký tá(o) bản\n",
            "Correct: dế mèn phiêu lưu ký tái bản\n",
            "\n",
            "Assume the first 7 chars are correct\n",
            "dòng su(o) --> dòng suố\n",
            "dòng su(o)i nguồn thịnh v(u) --> dòng suối nguồn thịnh vư\n",
            "Misspell: dòng su(o)i nguồn thịnh v(u)ợng\n",
            "Correct: dòng suối nguồn thịnh vượng\n",
            "\n",
            "Assume the first 7 chars are correct\n",
            "Misspell: \n",
            "Correct: dòng suối nguồn thịnh vượng\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('dòng suối nguồn thịnh vượng', '')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 226
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3iRRXJh-m5Hx",
        "outputId": "21232fc0-52d4-4699-ddbb-4e36c729781b"
      },
      "source": [
        "correct_text_lookahead(generate_model_lstm, \"dòng suối nnguồn thịnh vượng\")\n",
        "correct_text_lookahead(generate_model_lstm, \"dòng suối naaguồn thịnh vượng\")\n",
        "print()"
      ],
      "execution_count": 223,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Assume the first 7 chars are correct\n",
            "dòng suối n(n) --> dòng suối n\n",
            "Misspell: dòng suối n(n)guồn thịnh vượng\n",
            "Correct: dòng suối nguồn thịnh vượng\n",
            "\n",
            "Assume the first 7 chars are correct\n",
            "dòng suối n(a) --> dòng suối n\n",
            "dòng suối n(a)(a) --> dòng suối n\n",
            "Misspell: dòng suối n(a)(a)guồn thịnh vượng\n",
            "Correct: dòng suối nguồn thịnh vượng\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MeLBXetxnZvS"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}